## 머신러닝 키워드

**특성** : 데이터를 표현하는 하나의 성질.

**훈련** : 머신러닝 알고리즘이 데이터에서 규칙을 찾는 과정 (사이킷런에서 `fit()` 메서드의 역할)

**K-최근접 이웃 알고리즘** : 가장 가까운 이웃을 참고해 정답을 예측하는 간단한 머신러닝 알고리즘

**모델** : 머신러닝 알고리즘이 구현된 객체

**정확도** : 맞힌 개수 / 전데 데이터 개수 (사이킷런에서는 0 ~ 1 사이의 값)

**지도 학습** : 입력과 타깃을 전달해 모델을 훈련한 다음 새로운 데이터를 예측하는데 활용

**비지도 학습** : 타깃 데이터가 없음. 무엇을 예측하는 것이 아니라 입력 데이터에서 어떤 특징을 찾는데 활용

**훈련 세트** : 모델 훈련시 사용하는 데이터. 훈련 세트가 클수록 좋음.

**테스트 세트** : 전체 데이터에서 20~30%를 테스트 세트로 사용하는 경우가 많음.

**데이터 전처리** : 머신러닝 모델에 데이터를 주입하기 전에 가공하는 단계

**표준 점수** : 훈련 세트의 스케일을 바꾸는 대표적인 방법. 표준점수를 얻으려면 특성의 평균을 빼고 표준편차로 나눈다. 반드시 훈련 세트의 평균과 표준편차로 테스트 세트를 바꿔야 함.

**브로드 캐스팅** : 크기가 다른 넘파이 배열에서 자동으로 사칙 연산을 모든 행이나 열로 확장해 수행

**회귀** : 임의의 수치를 예측하는 문제 (타깃값도 임의의 수치가 됨)

**K-최근접 이웃 회귀** : k-최근접 이웃 알고리즘을 사용해 회귀 문제를 품. 가장 가까운 이웃샘플을 찾고 이 샘플들의 타깃값을 평균하여 예측으로 삼는다.

**결정계수(R^2)** : 대표적인 회귀 문제의 성능 측정 도구. 1에 가까울수록 좋고, 0에 가까울수록 성능이 나쁨.

**과대적합** : 모델의 훈련 세트 성능이 테스트 세트 성능보다 훨씬 높을 때 일어남. 모델이 훈련 세트에 너무 집착해서 데이터에 내재된 거시적 패턴을 감지하지 못함.

**과소적합** : 훈련 세트와 테스트 세트 성능이 모두 동일하게 낮거나 테스트 세트 성능이 오히려 더 높을 때 일어남. (더 복잡한 모델을 사용해 훈련 세트에 잘 맞는 모델을 만들어야 함)

**선형 회귀** : 특성과 타깃 사이의 관계를 가장 잘 나타내는 선형 방정식을 찾는다.(특성이 하나면 직선 방정식)
선형회귀가 찾은 특성과 타깃 사이의 관계는 선형 방정식의 **계수** 또는 **가중치**에 저장된다. 머신러닝에서 종종 가중치는 방정식의 기울기와 절편을 모두 의미함.

**모델 파라미터** : 선형 회귀가 찾은 가중치처럼 머신러닝 모델이 특성에서 학습한 파라미터를 말함.

**다항 회귀** : 다항식을 사용하여 특성과 타깃 사이의 관계를 나타냄. 비선형일수 있지만 여전히 선형 회귀로 표현

**다중 회귀** : 여러 개의 특성을 사용하는 회귀 모델. 특성이 많으면 선형 모델은 강력한 성능 발휘

**특성 공학** : 주어진 특성을 조합하여 새로운 특성을 만드는 일련의 작업 과정

**릿지** : 규제가 있는 선형 회귀 모델 중 하나이며 선형 모델의 계수를 작게 만들어 과대적합을 완화. 비교적 효과가 좋아 널리 사용하는 규제 방법

**라쏘** : 릿지와 달리 계수 값을 아예 0으로 만들 수 있는 또 다른 규제가 있는 선형 회귀 모델

**하이퍼파라미터** : 머신러닝 알고리즘이 학습하지 않는 파라미터. 사전에 사람이 지정해야하며 대표적으로 릿지와 라쏘의 규제 강도 alpha 파라미터가 있다.

**로지스틱 회귀** : 선형 방정식을 사용한 분류 알고리즘. 선형 회귀와 달리 시그모이드, 소프트맥스 함수를 사용해 클래스 확률 출력

**다중 분류** : 타깃 클래스가 2개 이상인 분류 문제.

